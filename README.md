# Task-1_SMS-Spam-Classification-Prediction-Model_-BharatIntern
Welcome to my spam classifier repository! This project utilizes MultinomialNB and various Natural Language Processing (NLP) techniques to distinguish between spam and non-spam messages

I experimented with multiple algorithms and evaluated their performance. The accuracy and precision metrics for different models.
Sms spam classifier
I have used an naive bayes model along with natural language processing to create this model

Porter Stemmer, Bag of words are the nlp techniques used for text preprocessing This model will be able to classify a message as spam or ham with an accuracy of 97 percent and precision is hundred percent.
Based on the comprehensive evaluation, Multinomial Naive Bayes emerged as the most accurate classifier for this spam detection task, achieving an accuracy of 97.10% and perfect precision.
Feel free to explore the repository to access code and instructions for implementing the MultinomialNB model or any other model of your choice for spam classification
The machine learning algorithm used here is MultinomialNB which uses bayes theorem from probability

For  SVC
Accuracy -  0.9758220502901354
Precision -  0.9747899159663865
For  KN
Accuracy -  0.9052224371373307
Precision -  1.0
For  NB
Accuracy -  0.9709864603481625
Precision -  1.0
For  DT
Accuracy -  0.9303675048355899
Precision -  0.8173076923076923
For  LR
Accuracy -  0.9584139264990329
Precision -  0.9702970297029703
For  RF
Accuracy -  0.9748549323017408
Precision -  0.9827586206896551
For  AdaBoost
Accuracy -  0.960348162475822
Precision -  0.9292035398230089
For  BgC
Accuracy -  0.9574468085106383
Precision -  0.8671875
For  ETC
Accuracy -  0.9748549323017408
Precision -  0.9745762711864406
For  GBDT
Accuracy -  0.9477756286266924
Precision -  0.92
For  xgb
Accuracy -  0.971953578336557
Precision -  0.943089430894309
